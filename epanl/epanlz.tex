\documentclass[a4paper,12pt]{article}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{datetime}
\usepackage{framed}
\usepackage{tabularx}
\usepackage{enumitem}
\usepackage{fancyref}
\usepackage{wrapfig}
\usepackage{pifont}

\usepackage{tikz}
\usetikzlibrary{fit,arrows,calc}

\usepackage{csquotes}
\renewcommand{\mkbegdispquote}[2]{\itshape}

\usepackage{data/circledsteps}
\input{data/style}

\usepackage{stmaryrd}
\usepackage{mathtools}


\title{有效过程与自然法则}
\date{1985 年 9 月 9 日}
\author{罗伯特·罗森}

\begin{document}

\maketitle{}

\renewcommand\contentsname{目录}
\setcounter{tocdepth}{2}
\tableofcontents

\section{引言}

现代科学史上最引人注目的思想交汇之一，发生在 1931 年哥德尔关于形式不可判定性的原始论文发表与 1943 年麦卡洛克和皮茨关于神经网络的著作发表之间的短短几年间。
在这 12 年中，逻辑学、数学、大脑理论和数字计算的可能性之间建立了基本的相互关系，而真实的数字计算仍然还差让人心动的那么一步来全面实现。人们当时认为，
半个世纪之后的今天依然如此认为，这些思想预示着一场革命，就像三个世纪前牛顿所取得的革命一样。

\begin{figure}[ht]
\centering
\includegraphics[height=1.5in]{images/kurt_godel.jpg}
\includegraphics[height=1.5in]{images/alan_turing.jpg}
\includegraphics[height=1.5in]{images/pitts_mcculloch_1949.png}
\caption{青年哥德尔；青年图灵；皮茨和麦卡洛克的合照}
\end{figure}

阿兰·图灵的名字在这些惊人发展的历史上是非凡的。正因为图灵，在他 1936 年发表的开创性论文中，通过构建以他的名字命名的“机器”类，他首次把这些相关的思想真正并列在一起。
一方面，图灵机是从人类进行数学计算的心理过程中明确推演出来的；另一方面，它们代表了逻辑或算法过程在数学中的形式化的体现；再一方面，通过使用“机器”这个术语，
它们又代表了，利用物质过程来扩展我们自己的数学能力（很快会通过数字计算机的发明来实现），并且在更深的层次上，为探索生命本身建立一个新的、强大的隐喻。

\begin{figure}[ht]
\centering
\includegraphics[height=2.0in]{images/turing_machine.jpg}
\caption{图灵机计算忙碌海狸问题的过程}
\end{figure}

在纯粹的数学/逻辑层面上，人们很快认识到，图灵机是体现算法概念的许多等价形式之一。反过来，算法被认为是一个解决问题的有效过程的缩影。
首先，一个有效过程意味着一种绝对必要性；它是一个推理链条，对从适当初始数据开始的每一个情况，它都必须要导向相应的那个答案或解答。
此外，算法是一个死记硬背的过程，一旦启动，在从数据到解答的无休止的过程中，不需要进一步的干预、省察和思考。这就是为什么，现在回想起来，
把它体现在一台“机器”上是如此自然，就像图灵做的那样。

\begin{wrapfigure}{r}{0.25\textwidth}
  \begin{center}
    \includegraphics[height=2.0in]{images/alonzo_church.jpg}
  \end{center}
  \caption{阿隆佐·邱奇}
\end{wrapfigure}

由于“有效过程”的概念是一个非形式的、直观的概念，而“算法”的概念是一个精确的形式化的数学概念，早期有人提出后者可以取代前者。
这正是邱奇论文(参见 Kleene1952)的实质内容， 该论文断言，任何人们想称之为“有效”的过程，已经可以通过一些适当编程的图灵机器来完成。

现在，严格地说，到目前为止所描述的所有讨论都是完全形式化的；它们发生在命题和产生规则的逻辑和数学宇宙中。从某种意义上说，它们都是“软件”。
然而，有趣之处主要集中在这样一个事实上：像“机器”或“有效”这样的术语具有非数学的内涵，这些内涵都属于自然物质现象的外部世界。
事实上，正如我们已经注意到的，图灵自己设计的数学机器是从现实世界的现象中抽象出来的，一个人在进行计算。这种暗示如此不可抗拒地传达出，
如果人类精神活动的这一方面可以“机械化”，为什么其他方面不可以呢？为什么不可以是全部呢？同样地，如果心理过程，包括在物质大脑中发生的事情(也即在硬件中)可以完全形式地表示，
为什么不能有其他类型的物质系统（也即其他硬件）可以做与大脑相同的事情？虽然还在胚胎阶段，在这里，我们看到了，“人工智能”的最广推论，以及许多其他的意涵。

但是，一旦我们承认“机器”或“有效”这样的词具有物质意义，我们就离开了数学的世界，进入了（最广义的）物理世界。正如我们已经提到的，图灵机是“纯软件”，
而物理学则相反，是“纯硬件”。因此，无论是好是坏，我们引入了硬件和软件之间的根本区别，它本身并不是我们开始时所使用的形式理论的一部分；同样，它也不是物理学的一部分。
正如我们将要看到的，这种区别是至关重要的，但是它是一种隐蔽的危险，藏在包罗万象的总称“机器”中。从马丁·戴维斯 1958 年出版的《可计算性和不可解性》一书中，
我们可以看到这种区别是如何悄无声息地出现的:

\begin{displayquote}
    我们怎么能排除某一天（也许是某个外星访客）给我们一个（也许是极其复杂的）设备或“神谕”来“计算”一个不可计算函数的可能性呢?
\end{displayquote}

这显然是在一个完全形式化的数学发展背景下提出的最具修辞性的反问句。但是我们在这里清楚地看到术语“机器”的任意性，它建立在真实硬件和逻辑软件之间的默认区别之上。

\begin{figure}[ht]
\centering
\includegraphics[height=2.0in]{images/turing_machine_oracle.png}
\caption{带神谕的图灵机}
\end{figure}

长期以来，作者一直为这一问题的深层认识论的结论所困扰。特别是，一旦我们承认“硬件”或物质系统进入我们的讨论（正如我们已经指出的那样，这从一开始就是明确无误的意图），
那么“有效过程”的概念会发生什么变化呢？很久以前（Rosen 1962），我考虑的问题是邱奇的论点在这个新的背景下意味着什么。
特别地：邱奇的论点是否是对物质本性的一个基本限制呢（类似于热力学定律排除了永动机），或者相反？ 如果邱奇的论点可以被自然过程破坏，那么递归性又会怎么样呢？

在这里回顾一下先前论点的要点可能是有用的。假设我们有一个物理系统 $S$（也许是戴维斯的外星“计算机”）。它的行为受到物理定律的支配，我们通过实验来了解这些定律。
一个典型的实验要么对系统做一些事情（例如，从外部扰动它），要么让系统对其环境做一些事情，然后观察或测量结果。显然，实验者的干预和测量的结果都是物质事件。
事件是由数字来描述或刻画其特性的，其数值是由应用的合适的量表来决定的（参见 Rosen1978）。为了简单起见，假设我们的实验干预 $\alpha$ 拥有的属性是这样一个数值 $r(\alpha)$，
而我们系统的结果行为由另一个这样的数字刻画。通过这种方式，我们的实验者可以生成一个数值表，它定义了一个从数字到数字的函数 $f$。
$$
r(\alpha) \mapsto \beta
$$

读者将会认识到，这个过程以典型输入输出的方式刻画了我们系统 $S$。函数 $f$ 的形式，清楚地告诉我们支配 $S$ 行为的规律。毕竟，这就是科学实验的全部功能。

这个实验过程在某种意义上是有效的。事实上，正如我们将在下面详细论述的那样，物质世界（例如，在系统 $S$ 中）的事件序列是由因果关系所支配的，这些因果关系将它们联系在一起，就像蕴涵关系将命题无可避免地联系在一起一样。
因此，如果我们的实验过程是可重复的（这意味着 $S$ 中相同的因果序列可以随意重建） ，那么邱奇的论点必须意味着任何输入输出函数 $1$，正如我们已经描述过的任何物质系统 $S$，也必须是递归的或可计算的。
否则，系统 $S$ 将正是戴维斯向我们保证排除在可能性之外的那种“计算机”。

从这个角度来看，邱奇的论文试图从软件（算法）的前提中得出关于硬件（物理学）的推论或结论。
冯 · 诺依曼关于“自我复制”的论点（Burks 1966; Arbib，本卷; 参见下文第5节）体现了另一种众所周知的同样尝试。
在这里，我们的目的是从一个关于计算的形式理论中学习关于物质系统（特别是有机体）的行为的一些东西。
不出所料，这类尝试风险极大，但如果能成功实现，回报将是巨大的。

\begin{figure}[ht]
\centering
\includegraphics[height=2.0in]{images/self_reprod.png}
\caption{运行中的第一个为人所知的自复制机}
\end{figure}

至少，我们可能已经看到，在形式理论中引入“硬件”的概念将产生一些特殊的结论。而当我们试图把“软件”的概念引入物理学时，互补的结论就出现在另一方面。
然而，这些特殊的结论将告诉我们一些关于这两者的有趣事情。在本文的其余部分，我们将探索这种可能性。

\section{形式系统中的邱奇论题}

邱奇论题的实质是，把任何形式系统中的逻辑推理与字符串处理等同起来。反过来，字符串处理或字处理是一种纯粹的语法活动。
当然，字符串处理正是图灵机所做的。尽管如此，从表面上看，这似乎是一个非常强的、或许有些过于强的条件，
它要求形式系统中的每一个推理，都应该只用语法项来表达；也就是说，从前提到结论的每一个步骤，都应该完全通过，对这些编码了的命题的符号进行操作来实现。

然而，我们可以有一个相当有力的理由来支持这个看起来不太可能的论题。
它源自于一种形式化的趋势，这种趋势始于欧几里德，随着非欧几里德几何的发现（作为形式系统，和上帝赋予的欧几里德几何一样是一致的几何学），
以及发现朴素集合论中悖论时的绝对绝望，这种混乱成为了一个紧迫问题。
大卫·希尔伯特首先对这种情况提出的形式主义的回应，恰恰是对任何语义内容都是空洞的数学；而辩称的不必要的语义，是困难的根源。
实际上，这把所有的数学变成了一种游戏，在这种游戏中，无意义的符号按照（一个有限的）任意语法规则来处理。
事实上，希尔伯特形式主义的全部意义，在于创造一个除了语法以外什么都没有的系统。

\begin{figure}[ht]
\centering
\includegraphics[height=2.0in]{images/hilbert.jpg}
\includegraphics[height=2.0in]{images/kleene.jpg}
\caption{大卫·希尔伯特；斯蒂芬·科尔·克莱尼}
\end{figure}

或许，这种形式主义计划最清晰的陈述是由 Kleene 1952 给出的

\begin{displayquote}
这一步（公理化）将不会完成，直到所有的未定义的性质或理论的技术性术语已表示成公理，它们对定理的推演是重要的。
然后应该有可能应用演绎法，把技术术语当作没有意义的单词。
因为，说它们对于定理的推导具有必要的意义，而不是说它们是从支配的公理中衍生出来的，
就等于是说，对于演绎来讲，它们并不都是可以用公理来表达重要性质的。
当技术性术语的含义因此被忽略了，我们就达到了形式公理学说的立场\ldots
因为我们已经完全从内容中抽象出来，只留下形式，我们说原始理论已经形式化了。
在这种结构中，理论不再是一个有意义的命题系统，而是一个作为词序列的句子系统，这些词序列依次是字母序列。
我们只是参照形式来说，哪些单词组合成句子，哪些句子是公理，哪些句子是其他句子的直接后果。
\end{displayquote}

显然，这里的想法是，总是可以用语法替换语义（“意义”），从而在逻辑上没有信息丢失；
任何涉及语义的推理，在形式化中都有纯粹的语法映像。

在这样的一个形式系统中，我们首先认为公理是真的。这种真的概念是可传递的；
如果公理为真，那么通过将系统的推理规则应用于它们而获得的符号序列也是如此；因而，真从公理传递到定理。
到目前为止，我们从来不需要从外部引入“真”的概念到系统中，就像从前一样；我们只是在推演的过程中构造真的命题（定理）。

\begin{figure}[ht]
\centering
\includegraphics[height=2.5in]{images/konigsberger_university.jpg}
\caption{哥德尔不完备性定理最早于 1930 年 9 月在柯尼斯堡大学的一个学术会议上发表}
\end{figure}

哥德尔著名的定理（Gödel 1931）中所包含的麻烦，源自于试图将这种内部真理的构造性概念与形式算术中预先赋予的外部真值进行比较； 正如哥德尔所示，它们并不匹配。
此外，看待图灵可判定性定理（Turing 1936-1937）的一种方式是，在给定的形式化中，没有内部推理机制来决定一个命题是否是一个定理(即，是真的)。
因此，我们知道，形式主义计划，其中只有纯粹的语法推论是允许的，是过于贫乏的，甚至不足以支撑数论。
也就是说，我们要么允许一些“非形式”的推理过程进入我们的系统，根据哥德尔定理，这些程序甚至在原则上都不能简化为语法； 要么永远把我们自己限制在数论的片段中。
这种“非形式”的推理过程是邱奇论题所不允许的，它们是无效的。

让我们用更熟悉的术语来讨论上述问题。 在普通(“柏拉图式”)数学中，它同时具有语法和语义学的方面，
我们知道，如果我们给定一个集合 $S$ ，通过规范结构可以从 $S$ 构造出许多其他集合。
例如，我们有幂集 $2^S$ ，我们有 $S$ 生成的自由代数结构(半群，群等) ，我们有从 $S$ 到 $S$ 的所有映射的集合 $H(S, S)$ ，
我们有笛卡儿积 $S \times S$ ，等等。
这些相关的集合赋予我们推理能力，这些能力具有逻辑关系的力量，但这些支配 $S$ 的数学系统的形式推演律，并不必然有足够的表达力。
例如，如果 $Q: S \mapsto S$ 是一个自同构(即 $H(S, S)$ 的一个元素) ，对 $s \in S $，我们可以说 $Q(s) = s^{\prime}$ 在 $s$ 和 $s^{\prime}$ 之间建立了一个蕴涵关系。
但是，这种“蕴涵”不一定与我们可以从支配系统的产生式规则中得出的结论相一致，也就是说，不必仅仅遵循系统的语法。
如果两者是一致的，可以说我们的 $Q$ 在系统中是可计算的；否则，就是不可计算的。在后一种情况下，根据邱奇的论点，我们不得不说映射 $Q$ 是无效的。
但是很明显，如果 $Q$ 有意义或存在，一旦它被赋予给我们，它就是有效的。

在形式系统的“全软件”的世界中，我们当然可以用任何喜欢的方式来限定自己。
因此，我们可以不允许我们自己拥有任意的自同构 $Q$，它是不能表示成纯粹的语法项的。
在这样一个世界里，也只有在这样一个世界里，邱奇论题才能不受限制地成立。
当然，这样一个正式的世界是否有趣，是另一个问题。正如我们将看到的，当我们允许“硬件”进入我们的世界时，情况会变得更加糟糕。

在讨论物质系统之前，我们应该先把形式系统中的命题编码到图灵机码带上，然后再把码带上的内容解码成系统中的命题。
很明显，在编码和解码方面，我们可以按照通常的直观意义使用“有效”一词；例如，我们熟悉的哥德尔编码，
显然是从句法到算术、然后再回来的有效映射。事实上，通过证明一个过程在某些形式系统中是有效的，或者说是递归的，
我们可以清楚地将编码、计算和解码结合到一个单独的图灵机中，这个机器可以完成所有三个步骤。
然而，我们在这里只是记下，编码和解码在逻辑上彼此不同，也不同于实际计算；
如果它们在某种意义上是“无效”的，那么邱奇论题可能会失败，即使计算本身是完全递归的。

\section{蕴涵与因果}

正如我们已经看到的，在形式系统的领域，邱奇论题辨析了“有效过程”的直觉概念与纯粹的语法观点下的字符串处理。

\begin{figure}[ht]
\centering
\includegraphics[height=2.5in]{images/boltzmanns_molecule.jpg}
\caption{玻尔兹曼设想的由原子构成的分子}
\end{figure}


也就是说，任何可以在系统内“有效地”执行的蕴涵，都可以通过一套有限的产生规则来执行，这套规则操作于从一个有限字母表中取出的有限的符号串。
我们还指出，当我们在处理物质世界时（相对于形式的数学和逻辑），蕴涵的观念被因果关系的观念所取代。
尽管如此，我们仍然可以保留“有效”过程的想法。 在这种情况下，邱奇论题意味着任何因果序列都可以用相应的递归过程来表示；
也就是说，任何因果序列都可以用纯粹的句法手段来描述。 如果这是真的，它当然会严重限制物理学的发展。
是否自然法则本身可以表达成纯粹的语法项，或者它们是否可以拥有一个内在的语义组成部分不能被有限形式化，问题绝不仅仅限于此。
值得注意的是，数学中的形式化（即纯粹的句法）与理论科学中的类似趋势是完全平行的。
事实上，原子论（或者现在的“基本粒子”理论）的全部推动力是将所有物质过程简化到终极组成单元的运动，而没有任何内部结构（“意义”），
只拥有瞬时位置（“构型”）和位置的瞬时导数。推动这些终极单元的力量与形式系统中的产生式规则完全相同。
因此，一个物质系统在给定力的影响下所追踪到的路径或轨迹是形式定理的类比，以初始条件为公理。
物质系统中事件之间的因果关系可以与描述这些事件的命题之间的蕴涵关系相联系的观点是理论科学的必要条件。
事实上，过去被称为自然法则的信念要求：
\begin{enumerate}[label=(\alph*)]
\item 我们在外部世界中感知到的事件序列不是任意的或异想天开的，而是受到明确规则的支配（这就是因果关系）；
\item 这些规则可以清楚地表达出来，以便人类头脑能够理解。
\end{enumerate}
综上所述，自然法则的这种表述精确地断言，物质系统中的因果关系可以被引导到一个形式化的（终极的，数学的）命题系统的一致性蕴涵关系中。

这种情况可以最简洁地用图式一来表示（参见图9）。

\begin{figure}[ht]
\centering
\begin{tikzpicture}
[round/.style={rounded corners=1.5mm, minimum width=1cm, inner sep=2mm, above right, draw, align=center, text width=7mm}]
    \node[round] (N) at (0,0) {自然系统};
    \node[round] (F) at (6,0) {形式系统};
    \path[draw, thick, bend left=-45]
        ($(N.east)+(0,-1.0)$) edge[->] node[near start] {\hspace{+6em}\ding{193}编码} ($(F.west)+(0,-1.0)$);
    \path[draw, thick, bend left=-45]
        ($(F.west)+(0,1.0)$) edge[->] node[near start] {\hspace{-6em}\ding{195}解码} ($(N.east)+(0,1.0)$);
    \path[draw, thick, bend left=-45]
        ($(N.west)+(0,+0.8)$) edge[->] node {\hspace{-3em}\ding{192}因果} ($(N.west)+(0,-0.8)$);
    \path[draw, thick, bend left=-45]
        ($(F.east)+(0,-0.8)$) edge[->] node {\hspace{+3em}\ding{194}蕴涵} ($(F.east)+(0,+0.8)$);
\end{tikzpicture}
\caption{图式一}
\end{figure}

我们说，当以下的交换性成立时，图表左侧的自然系统和右侧的形式系统之间存在一种建模关系:

\begin{equation}
\Circled{1} = \Circled{2} + \Circled{3} + \Circled{4}
\end{equation}
\newline

也就是说，无论我们是仅仅作为观察者坐在那里，观察自然系统中事件的展开序列，还是我们
\begin{enumerate}[label=(\alph*)]
\item 将自然系统的某些性质编码成形式；
\item 然后利用形式系统的蕴涵结构导出定理；
\item 再将这些定理解码成关于自然系统本身的命题（预测）
\end{enumerate}
我们都得到了同样的答案。当图表交换时，我们在自然系统的因果特征和形式系统的蕴涵结构之间建立了一个一致性。
我们可以说形式系统是自然系统的模型，或者说，自然系统是形式系统的实现。

这些小图表本身包含许多丰富而重要的认识论属性，我们不能在这里进入；要进行更全面的讨论，请参阅 Rosen 1985。

一旦我们建立了一个形式的系统，作为某种自然过程的模型，我们就离开了科学的领域，进入了数学的领域。
然后，我们可以像对待其他任何形式系统一样对待模型。特别是，我们可以看看它纯粹的语法方面，
我们可以立即辨认出邱奇论题里的“有效”过程，并问这些过程是否耗尽了系统本身的蕴涵性资源。

通过这种方式，我们可以构建一个纯语法的原本的自然系统的“机器”模型，如 图10 所示。

\begin{figure}[ht]
\centering
\begin{tikzpicture}
[round/.style={rounded corners=1.5mm, minimum width=1cm, inner sep=2mm, above right, draw, align=center, text width=7mm}]
    \node[round] (N) at (0,0) {自然系统};
    \node[round] (F) at (6,0) {形式系统};
    \node[round] (M) at (12,0) {机　　器};
    \path[draw, thick, bend left=-45]
        ($(N.east)+(0,-1.0)$) edge[->] node[near start] {} ($(F.west)+(0,-1.0)$);
    \path[draw, thick, bend left=-45]
        ($(F.west)+(0,1.0)$) edge[->] node[near start] {} ($(N.east)+(0,1.0)$);
    \path[draw, thick, bend left=-45]
        ($(N.west)+(0,+0.8)$) edge[->] node {\hspace{-3em}因果} ($(N.west)+(0,-0.8)$);
    \path[draw, thick, bend left=-45]
        ($(F.east)+(0,-0.8)$) edge[->] node {\hspace{+3em}蕴涵} ($(F.east)+(0,+0.8)$);
    \path[draw, thick, bend left=-45]
        ($(M.east)+(0,-0.8)$) edge[->] node {\hspace{+5em}字串处理} ($(M.east)+(0,+0.8)$);
\end{tikzpicture}
\caption{图式二}
\end{figure}


This can be seen by looking only at the outer two systems, and forgetting about our original model, which now plays the role of a "transducer"
between them.

However, when we do this, the following points must be explicitly noticed: (a) the encoding and decoding arrows between them (the
dotted arrows in Figure 2) cannot be described as effective in any formal
sense, and (b) these encoding and decoding arrows involve exclusively the
input and output strings of the machines inhabiting the right-most box. Both
of these observations are important. We shall briefly discuss them each in
turn.

In applying Church's Thesis to formal systems, we noted above that the
corresponding encoding and decoding arrows themselves represented formal processes, which could in fact be amalgamated into
the Thesis itself. However, when we wish to compare a natural system, governed by causality, with a formal system, governed by
implication, this is no longer the case. The encoding instruments, or transducers, are now themselves material systems;
i.e., governed by causality and not by implications. As noted above, they are (in the broadest sense) meters. Since these meters are governed by
causality, anything they do is effective in a material sense. But it is clear that a formalization of the encoding process would require more models;
these would in turn require their own encoding and decoding processes, which would require more models, etc., an infinite regress.
It is precisely this fact which makes "the measurement problem" so hard in physics. The question as to whether this potential infinite regress
can be terminated at some finite point is a deep epistemological question about the nature of the world, with close ties to such things as
reductionism. We cannot of course enter into such matters here; we will merely assume that a set of meters or other transducers
from the natural world to input tapes is given, and that Church's Thesis can be investigated relative to these encodings
(which are then, by hypothesis, effective in the material sense).

Our second observation is also epistemologically important. It says that
all relevant features of a material system, and of the model into which it
was originally encoded (cf. Figure 1), are to be expressed as input strings to
be processed by a machine whose structure itself encodes nothing. That is to
say, the rules governing the operation of these machines, and hence the entire
inferential structure of the string-processing system themselves, have no
relation at all to the material system being encoded. The'only requirement
is that the requisite commutativity hold, as expressed in Section 1 above,
between the encoding on input strings and the decoding of the resultant
output strings. As we shall see, this is the essence of simulation.

We have already noted that Church's Thesis amounts to asserting that
all causal relationships can be expressed in purely syntactic terms. We can
formulate the Thesis still more sharply now: relative to any given encoding
of a natural system into input strings, the string-processing machinery itself
must not encode any aspect of the material system.  That is to say, the
"hardware" of the machines must be totally independent of the "hardware"
generating the strings to be processed. If this cannot be done, then Church's
Thesis cannot be true.

Given the above, Church's Thesis asserts that the Turing machines constitute
a class of universal simulators for all material processes. There are
then two questions to be asked: (a) is it true? and (b) if so, what does it
mean?

\section{邱奇论题在物理上是正确的吗？}

The upshot of the argument of the preceding sections is the following. Na-
ture provides us with a plethora of material processes which we would want
to call "effective". These processes are (we suppose) governed by causality,
and not by implication or production rules, as in a formal system. In these
terms, Church's Thesis can be expressed as follows. Given any such process,
we can encode appropriate propositions about the natural system generating
it onto a set of input tapes to a Turing machine; and the corresponding output
tapes can be decoded so as to perfectly simulate the process in question.
Equivalently, Church's Thesis asserts that all "information" about material
processes, and hence all of Natural Law, can be expressed in purely syntactic
terms.

We know from Gliders Theorem that sufficiently rich formal systems
always contain inferences which cannot be obtained syntactically.  More
specifically, given any encoding of propositions of the system onto input
tapes to Turing machines, there will be propositions of the system which are
"true" but will never appear on any output tape. The processes by which the
"truth" of such inferences are established are thus ineffective; they cannot
in principle be simulated by any Turing machine in the given encoding. We
can always change the encoding, of course, but this will not change Gliders
conclusion.

Thus, in formal systems, we already find that a purely syntactical encoding
will in some sense lose information. The information lost must then
pertain to an irreducible, unformalizable semantic component in the original
inferential structure. By changing the encodings, we can shift to some
extent where this semantic information resides, but we cannot eliminate it.

By itself, this result of Godel does not bear on the physical truth of
Church's Thesis, since it is a purely formal result. But it is in fact suggestive
of how the physical font of Church's Thesis might be verified or falsified.

As we have seen above, the manner in which we compare material processes with formal ones is through the establishment of
modeling relations, as diagrammed in Figure 1 above. Formal models of material systems are
then perfectly good formal systems, whose inferential structures by definition reflect causal processes in the natural system being modeled.
Thus, if a model, arising in this fashion, should fall within the purview of Gliders
argument, this would at least be strong evidence that Church's Thesis is
false as a physical proposition. Stated another way, there would exist physical processes which could effectively compute
nonrecursive functions. It would also mean that Natural Law cannot be expressed entirely in syntactical terms.

The obvious thing to look for, then, is a model of a material system
which is rich enough as a formalism to "do arithmetic". The formalisms
which physics provides, as models of purely physical systems, are unfortunately
extremely impoverished, considered simply as formal systems. But,
as we have argued elsewhere, these formalisms are in fact highly nongeneric
and do not suffice to image material systems like organisms (cf. Rosen, in
press). One way of expressing this nongenericity is precisely in terms of the
way they image causal structures. When this nongenericity is lifted, a new
class of (potential) models is obtained in which the image of causal structure
is infinitely richer and more complicated. Since it is precisely the formal
imaging of causal structures which is at the heart of Church's Thesis, we may perhaps find in these formalisms many processes
which are causally effective, but mathematically ineffective. This would mean that the behavior of such systems must contain
an irreducible semantic component, one intimately related to the complexity of the system.

A different approach was taken long ago by John Myhill (cf. Myhill 1966).
He was able to show that, modulo some idealizations regarding measurement and performance tolerances, there are already
classical analog devices(analog computers) which could "compute" nonrecursive functions. Such systems would thus already
manifest behaviors which could not be predicted by any purely syntactic encoding, and hence would also have an irreducible
semantic aspect.

Finally, we have already mentioned that Newtonian particle mechanics, and more recently, the unified physical theories based on elementary particles,
are in themselves an attempt to express the Laws of Nature in purely syntactic terms. Insofar as any material system is comprised of such "meaningless"
(i.e., structureless) elementary subunits, these theories at heart assert that to understand any behavior of any
such system it suffices to describe it in terms of these subunits and their interactions. As noted earlier, this is the essence of reductionism.

In these terms, the familiar Laplacian Spirit is a purely syntactical concept: the embodiment of Church's Thesis if he could exist.  As a matter
of fact, he could not exist (or at any rate, not as a material system built of particles himself), for reasons we have already indicated.
But even if he could exist, he would be a very poor biologist, for example; organisms, and open systems in general, are constantly turning over their
constituent particles. Thus, to even find an organism, let alone follow it in time, he would need to supplement his purely syntactical
information with other (semantic) information not formalizable within his system.

Thus, for a variety of reasons, there is cause to believe that Church's Thesis fails as a physical proposition. Nevertheless,
as we have seen, to state and analyze the Thesis in material terms touches on some of the deepest and most basic aspects of theoretical science.

\section{模拟的角色}

We have already alluded above to the use of the Turing machines both
as metaphors for the material world and as effective descriptions of that
world.  In both cases, though in different ways, we seek to draw conclusions
about material processes from a purely syntactic formalism. In this final section,
I will very briefly consider one well-known example of this:
the "self-reproducing automata" of von Neumann (Burks 1966; Arbib, this volume).

The basis of von Neumann's argument was the inference of the existence of a "universal constructor" from Turing's
argument for a universal simulator (computer).  On the purely formal side, von Neumann constructed
a universe ("cellular space") of intercommunicating Turing machines arranged along some regular geometric array,
like the cells in a multicellular organism, or ,the neurons in a brain, or atoms in a crystal. Each machine
communicates with its nearest neighbors in the array. In the obvious fashion, the array as a whole changes "state" in time.
The question was whether some sub-array ("tessellation automaton") could induce certain interesting behaviors in its complement,
which could be interpreted as construction, replication, growth, development, evolution, and so on.

At the same time, von Neumann clearly believed that a "universal constructor" could exist as hardware. He envisaged equipping a Turing machine
with sensors, so that it could "read" a blueprint, and with effectors,
so that it could extract physical components from its environment, and
assemble them as instructed by the blueprint being read. (An "effector",
in this context, is a transducer from numbers to things, i.e., an "inverse
meter".) The idea was -that both computation and construction were algorithmic processes,
and therefore whatever was true of the one must be true
of the other.

Von Neumann also felt that the cellular spaces were not merely formal constructs, but actually comprised models of real-world
constructors and their activities. In this, he was tacitly assuming Church's Thesis in its strongest form.

We have argued elsewhere (cf. Rosen 1985), on grounds of causality, that
any inference regarding a material universal constructor from the existence
of a formal universal computer is unjustified.  In that argument, we essentially
showed that there was no intrinsic way of distinguishing between
those input strings which encode "real-world information" and those which
do not. Thus there was no way to distinguish between a computation which
could be claimed to simulate a "real-world" process, and one which has no
such realization.

Conversely, we can also see that the falsity of Church's Thesis means that there are aspects of material processes which cannot be formalized with any given encoding.
Thus there are (a) formal constructions without material counterpart, and conversely, (b) m material constructions without formal counterpart.
Therefore, on both counts, von Neumann's argument is without material content, and merely involves the familiar equivocation on
the terms "automaton" (or "machine") and "construction".

These considerations show how dangerous it can be to extrapolate unrestrictedly from formal systems to material ones.
The danger arises precisely from the fact that computation involves only simulation, which allows the establishment of
no congruence between causal processes in material systems and inferential processes in the simulator. We therefore lack precisely
those essential features of encoding and decoding which are required for such extrapolations. Thus, although formal simulators can be of
great practical and heuristic value, their theoretical significance is very sharply circumscribed, and they must be used with the greatest caution.

There are, of course, many other ramifications of Church's Thesis which we cannot touch on in this brief space. Its main role, as we have seen,
is to separate out what is syntactic in a formal system from what is not; when the formal system is also a model of a material system,
Church's Thesis does the same for causal relations. The Thesis in fact raises a host of deep questions about Natural Law, about causality,
about modeling, and about the material realization of formalisms. Its central feature, the Turing machines, embody the essence of syntactics
or string processing in a single, conceptually rich package. Even if (as I believe) Church's Thesis fails, it does so in a most instructive way.
Its implications for the material sciences, and especially for biology, have barely begun to be explored.

\end{document}




